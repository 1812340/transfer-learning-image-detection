{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd5b0155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Waqas\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import keras \n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36c828d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4200 files belonging to 2 classes.\n",
      "Using 3780 files for training.\n",
      "Found 4200 files belonging to 2 classes.\n",
      "Using 840 files for validation.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "image_size = (150, 150)  # Adjust the size as needed\n",
    "\n",
    "data_dir='C:/National college/Foundation of artificial intelligent/project/TB_Chest_Radiography_Database'\n",
    "train=keras.utils.image_dataset_from_directory(data_dir,image_size=image_size,\n",
    "                                                validation_split=0.1,\n",
    "                                                label_mode='categorical',\n",
    "                                                subset='training',seed=123)\n",
    "val=keras.utils.image_dataset_from_directory(data_dir,image_size=image_size,\n",
    "                                             label_mode = 'categorical',\n",
    "                                                validation_split=0.2,\n",
    "                                                subset='validation',seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3f11d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train=train.map(lambda x,y:(x/255,y))\n",
    "val=val.map(lambda x,y:(x/255,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e68ab18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Waqas\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Waqas\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "VGG_model = Sequential()\n",
    "\n",
    "pretrained_model= keras.applications.VGG16(include_top=False,\n",
    "                   input_shape=(150,150,3),\n",
    "                   pooling='max',classes=4,\n",
    "                   weights='imagenet')\n",
    "\n",
    "\n",
    "VGG_model.add(pretrained_model)\n",
    "VGG_model.add(Flatten())\n",
    "VGG_model.add(Dense(512, activation='relu'))\n",
    "VGG_model.add(BatchNormalization())  # Batch Normalization layer\n",
    "VGG_model.add(Dropout(0.5))\n",
    "\n",
    "VGG_model.add(Dense(2, activation='softmax'))\n",
    "pretrained_model.trainable=False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35537837",
   "metadata": {},
   "outputs": [],
   "source": [
    "VGG_model.compile(optimizer=keras.optimizers.Adam(0.0001),\n",
    "              loss=keras.losses.CategoricalCrossentropy(),metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73212233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Waqas\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Waqas\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "119/119 [==============================] - 321s 3s/step - loss: 0.5835 - accuracy: 0.7479 - val_loss: 0.2226 - val_accuracy: 0.9429\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1ff22d9a950>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VGG_model.fit(train,epochs=1,\n",
    "                 validation_data=val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05925978",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waqas\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "VGG_model.save(\"C:/National college/Artificial Intelligence Driven Decision Making (MSCAI1)/tuberculosis.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b8143ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 50s 2s/step - loss: 0.2226 - accuracy: 0.9429\n",
      "Validation Loss: 0.2225508689880371\n",
      "Validation Accuracy: 0.9428571462631226\n",
      "27/27 [==============================] - 53s 2s/step\n",
      "Validation Precision: 0.17142857142857143\n",
      "Validation Recall: 0.12244897959183673\n",
      "Validation F1-score: 0.14285714285714288\n",
      "Confusion Matrix:\n",
      "[[606  87]\n",
      " [129  18]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.87      0.85       693\n",
      "           1       0.17      0.12      0.14       147\n",
      "\n",
      "    accuracy                           0.74       840\n",
      "   macro avg       0.50      0.50      0.50       840\n",
      "weighted avg       0.71      0.74      0.73       840\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "loss, accuracy = VGG_model.evaluate(val)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Validation Loss:\", loss)\n",
    "print(\"Validation Accuracy:\", accuracy)\n",
    "\n",
    "# Calculate precision, recall, and F1-score\n",
    "y_pred = VGG_model.predict(val)\n",
    "y_pred_class = np.argmax(y_pred, axis=1)\n",
    "y_true = np.concatenate([y for x, y in val], axis=0)\n",
    "y_true_class = np.argmax(y_true, axis=1)\n",
    "\n",
    "precision = precision_score(y_true_class, y_pred_class)\n",
    "recall = recall_score(y_true_class, y_pred_class)\n",
    "f1 = f1_score(y_true_class, y_pred_class)\n",
    "\n",
    "print(\"Validation Precision:\", precision)\n",
    "print(\"Validation Recall:\", recall)\n",
    "print(\"Validation F1-score:\", f1)\n",
    "\n",
    "# Confusion matrix\n",
    "conf_mat = confusion_matrix(y_true_class, y_pred_class)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_mat)\n",
    "\n",
    "# Classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_true_class, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83d09dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
